

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Voice Activity Detector &mdash; webrtc_tutorial 1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Automatic Gain Control" href="audio_agc.html" />
    <link rel="prev" title="Acoustic Echo Canceller" href="audio_aec.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> webrtc_tutorial
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../outline.html">目录</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1.basic/index.html">1. WebRTC 基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2.transport/index.html">2. WebRTC 传输</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">3. WebRTC 媒体</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="overview.html">WebRTC 媒体概论</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="webrtc_audio.html">WebRTC 音频</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="audio_basic.html">Audio Basic</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_level.html">Audio Level</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_api.html">Web Audio API</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_qos.html">Audio QoS</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_aec.html">Acoustic Echo Canceller</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Voice Activity Detector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vad-in-codec">VAD in codec</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cng">CNG</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vad-definition">VAD definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="#algorithm">Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="audio_agc.html">Automatic Gain Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_ans.html">Automatic Noise Suppression</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_worklet.html">Audio worklet</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_quality.html">Audio Quality</a></li>
<li class="toctree-l3"><a class="reference internal" href="audio_analysis.html">Audio Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="opus.html">Opus Codec</a></li>
<li class="toctree-l3"><a class="reference internal" href="webrtc_audio.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="webrtc_audio.html#plc">PLC</a></li>
<li class="toctree-l3"><a class="reference internal" href="webrtc_audio.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="webrtc_video.html">WebRTC 视频</a></li>
<li class="toctree-l2"><a class="reference internal" href="webrtc_qos.html">WebRTC QoS</a></li>
<li class="toctree-l2"><a class="reference internal" href="webrtc_fec.html">WebRTC FEC</a></li>
<li class="toctree-l2"><a class="reference internal" href="webrtc_rtx.html">WebRTC RTX</a></li>
<li class="toctree-l2"><a class="reference internal" href="webrtc_rcc.html">WebRTC 拥塞控制</a></li>
<li class="toctree-l2"><a class="reference internal" href="jitter_buffer.html">Jitter Buffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="insertable_stream.html">Insertable Stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="web_codec.html">Web Codecs</a></li>
<li class="toctree-l2"><a class="reference internal" href="web_transport.html">Web Transport</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../4.practice/index.html">4. WebRTC 实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5.tool/index.html">5. WebRTC 工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6.misc/index.html">6. WebRTC 关联技术</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">webrtc_tutorial</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">3. WebRTC 媒体</a> &raquo;</li>
        
          <li><a href="webrtc_audio.html">WebRTC 音频</a> &raquo;</li>
        
      <li>Voice Activity Detector</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/3.media/audio_vad.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="voice-activity-detector">
<h1>Voice Activity Detector<a class="headerlink" href="#voice-activity-detector" title="Permalink to this headline">¶</a></h1>
<table class="docutils align-default">
<colgroup>
<col style="width: 32%" />
<col style="width: 68%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Abstract</strong></p></td>
<td><p>Voice Activity Detector</p></td>
</tr>
<tr class="row-even"><td><p><strong>Authors</strong></p></td>
<td><p>Walter Fan</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Status</strong></p></td>
<td><p>WIP</p></td>
</tr>
<tr class="row-even"><td><p><strong>Updated</strong></p></td>
<td><p>2021-12-22</p></td>
</tr>
</tbody>
</table>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#overview" id="id2">Overview</a></p></li>
<li><p><a class="reference internal" href="#vad-in-codec" id="id3">VAD in codec</a></p></li>
<li><p><a class="reference internal" href="#cng" id="id4">CNG</a></p></li>
<li><p><a class="reference internal" href="#vad-definition" id="id5">VAD definition</a></p></li>
<li><p><a class="reference internal" href="#algorithm" id="id6">Algorithm</a></p></li>
<li><p><a class="reference internal" href="#reference" id="id7">Reference</a></p></li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id2">Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Voice activity detection (VAD), also known as speech activity detection or speech detection, is the detection of the presence or absence of human speech, used in speech processing.</p>
<p>The main uses of VAD are in speech coding and speech recognition. It can facilitate speech processing, and can also be used to deactivate some processes during non-speech section of an audio session: it can avoid unnecessary coding/transmission of silence packets in Voice over Internet Protocol (VoIP) applications, saving on computation and on network bandwidth.</p>
<p>VAD is an important enabling technology for a variety of speech-based applications.</p>
<p>Therefore, various VAD algorithms have been developed that provide varying features and compromises between latency, sensitivity, accuracy and computational cost.</p>
<p>Some VAD algorithms also provide further analysis, for example whether the speech is voiced, unvoiced or sustained. Voice activity detection is usually independent of language.</p>
</div>
<div class="section" id="vad-in-codec">
<h2><a class="toc-backref" href="#id3">VAD in codec</a><a class="headerlink" href="#vad-in-codec" title="Permalink to this headline">¶</a></h2>
<p>VAD in Opus determines whether a frame is sent out as empty (DTX) or not.</p>
<p>If speech is classified as silence (false negative), the frame will be empty and speech will be lost
False negative rate(FNR) needs to be as close to zero as possible when DTX is enabled
the different VAD in opus codec under different complexity, VAD ON will tigger DTX ON（400ms）,and VAD’s decision will decide whether we should play CNG on playback.</p>
<p>the RNN-VAD is used when complexity setting &gt;=7(float),which means when complexity &lt;7,we use traditional VAD.</p>
</div>
<div class="section" id="cng">
<h2><a class="toc-backref" href="#id4">CNG</a><a class="headerlink" href="#cng" title="Permalink to this headline">¶</a></h2>
<p>There is a Real-time Transport Protocol (RTP) Payload for Comfort Noise (CN).
(refer to RFC 3389 )</p>
<p>The payload format provides a minimum interoperability specification for communication of comfort noise parameters.  The comfort noise analysis and synthesis as well as the Voice Activity Detection (VAD) and DT</p>
<p>Two popular types of VAD/CNG schemes are included in G.711.</p>
<p>The noise power levels in both VAD/CNG methods are expressed in −dBov to interoperate with each other.</p>
<p>The unit “dBov” is the dB level relative to the overload of the system. It is not a Volts reference for dBV.</p>
<p>For example, in the case of μ-law-based coding, the maximum sine wave signal power without distortion is 3.17 dBm with amplitude ±8159. Square wave power is 3 dB more than sine wave power. The maximum possible power of signal from a square wave with an amplitude of ±8159 is 0 dBov as reference, which corresponds to a 6.17-dBm power level in the μ-law system. Hence, 0 dBov = 6.17 dBm is used in μ-law system. Sine and square wave power levels and signal amplitudes are shown in Fig. 4.1(c). Representation relative to the overload point of a system is particularly useful for digital implementations, because one does not need to know the relative calibration of the analog circuitry.</p>
</div>
<div class="section" id="vad-definition">
<h2><a class="toc-backref" href="#id5">VAD definition</a><a class="headerlink" href="#vad-definition" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>SILK VAD(SNR based)</p></li>
</ul>
<p>SILK VAD is based on SNR, which estimates the noise level to determine speech activity
The Voice Activity Detector (VAD) generates a measure of speech activity by combining the signal-to-noise ratios (SNRs) from 4 separate frequency bands. In each band the background noise level is estimated by smoothing the inverse energy over time frames.
Multiplying this smoothed inverse energy with the subband energy gives the SNR.</p>
<ul class="simple">
<li><p>Opus VAD(RNN based)</p></li>
</ul>
<p>Opus VAD uses recursive neural network based on GRU units to perform both speech/music and speech/silence classification:</p>
</div>
<div class="section" id="algorithm">
<h2><a class="toc-backref" href="#id6">Algorithm</a><a class="headerlink" href="#algorithm" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>There may first be a noise reduction stage, e.g. via spectral subtraction.</p></li>
<li><p>Then some features or quantities are calculated from a section of the input signal.</p></li>
<li><p>A classification rule is applied to classify the section as speech or non-speech – often this classification rule finds when a value exceeds a certain threshold.</p></li>
</ol>
<p>There may be some feedback in this sequence, in which the VAD decision is used to improve the noise estimate in the noise reduction stage, or to adaptively vary the threshold(s). These feedback operations improve the VAD performance in non-stationary noise (i.e. when the noise varies a lot).[citation needed]</p>
<p>A representative set of recently published VAD methods formulates the decision rule on a frame by frame basis using instantaneous measures of the divergence distance between speech and noise.[citation needed] The different measures which are used in VAD methods include spectral slope, correlation coefficients, log likelihood ratio, cepstral, weighted cepstral, and modified distance measures.[citation needed]</p>
<p>Independently from the choice of VAD algorithm, a compromise must be made between having voice detected as noise, or noise detected as voice (between false positive and false negative). A VAD operating in a mobile phone must be able to detect speech in the presence of a range of very diverse types of acoustic background noise. In these difficult detection conditions it is often preferable that a VAD should fail-safe, indicating speech detected when the decision is in doubt, to lower the chance of losing speech segments. The biggest difficulty in the detection of speech in this environment is the very low signal-to-noise ratios (SNRs) that are encountered. It may be impossible to distinguish between speech and noise using simple level detection techniques when parts of the speech utterance are buried below the noise.</p>
</div>
<div class="section" id="reference">
<h2><a class="toc-backref" href="#id7">Reference</a><a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Voice_activity_detection">https://en.wikipedia.org/wiki/Voice_activity_detection</a></p></li>
<li><p><a class="reference external" href="https://github.com:wiseman/py-webrtcvad.gits">https://github.com:wiseman/py-webrtcvad.gits</a></p></li>
<li><p><a class="reference external" href="https://github.com/snakers4/silero-vad">https://github.com/snakers4/silero-vad</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/snakers4/silero-vad/blob/master/silero-vad.ipynb">https://colab.research.google.com/github/snakers4/silero-vad/blob/master/silero-vad.ipynb</a></p></li>
<li><p><a class="reference external" href="https://chromium.googlesource.com/external/webrtc/+/518c683f3e413523a458a94b533274bd7f29992d/webrtc/modules/audio_processing/vad/voice_activity_detector.h">https://chromium.googlesource.com/external/webrtc/+/518c683f3e413523a458a94b533274bd7f29992d/webrtc/modules/audio_processing/vad/voice_activity_detector.h</a></p></li>
<li><p><a class="reference external" href="https://www.mathworks.com/matlabcentral/fileexchange/78895-google-webrtc-voice-activity-detection-vad-module">https://www.mathworks.com/matlabcentral/fileexchange/78895-google-webrtc-voice-activity-detection-vad-module</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="audio_agc.html" class="btn btn-neutral float-right" title="Automatic Gain Control" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="audio_aec.html" class="btn btn-neutral float-left" title="Acoustic Echo Canceller" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, walter.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>